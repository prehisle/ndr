# NDR 维护指南

## 目录
- [1. 项目概述](#1-项目概述)
- [2. 环境要求](#2-环境要求)
- [3. 开发环境搭建](#3-开发环境搭建)
- [4. 项目架构](#4-项目架构)
- [5. 数据库维护](#5-数据库维护)
- [6. 常见维护任务](#6-常见维护任务)
- [7. 故障排查](#7-故障排查)
- [8. 性能优化](#8-性能优化)
- [9. 安全配置](#9-安全配置)
- [10. 监控与日志](#10-监控与日志)
- [11. 部署指南](#11-部署指南)
- [12. 备份与恢复](#12-备份与恢复)

---

## 1. 项目概述

### 1.1 项目简介
NDR (通用资料管理微服务) 是一个基于 FastAPI + SQLAlchemy + PostgreSQL 的文档和节点管理系统，提供:
- 文档生命周期管理 (CRUD、软删除、版本控制)
- 层级节点树管理 (基于 PostgreSQL ltree)
- 节点-文档关系管理
- 完整的审计跟踪

### 1.2 技术栈
| 组件 | 版本 | 用途 |
|------|------|------|
| Python | 3.11+ | 主要编程语言 |
| FastAPI | 0.115.0 | Web 框架 |
| SQLAlchemy | 2.0.34 | ORM |
| PostgreSQL | 16+ | 数据库 |
| Alembic | 1.13.2 | 数据库迁移 |
| Uvicorn | 0.30.0 | ASGI 服务器 |
| Prometheus | - | 指标收集 |

### 1.3 设计约束
- **无缓存层**: NDR 本身不包含缓存，所有缓存策略由调用方负责
- **单一职责**: 专注于文档和节点的生命周期管理
- **幂等性**: 支持 Idempotency-Key 头实现分布式幂等操作
- **软删除**: 默认软删除，支持恢复和永久清除

---

## 2. 环境要求

### 2.1 生产环境
- **操作系统**: Linux (推荐 Ubuntu 20.04+/Debian 11+)
- **Python**: 3.11 或更高版本
- **PostgreSQL**: 16+ (必须启用 ltree、btree_gist、btree_gin 扩展)
- **内存**: 最低 2GB RAM (推荐 4GB+)
- **CPU**: 2 核心以上
- **磁盘**: 至少 10GB 可用空间 (根据数据量调整)

### 2.2 开发环境
- **Python**: 3.11+
- **PostgreSQL**: 16+ (本地或容器)
- **Docker & Docker Compose**: 最新稳定版 (可选，用于容器化开发)
- **Git**: 2.x+
- **编辑器**: 推荐 VS Code (配合 Python 扩展)

### 2.3 必需的 PostgreSQL 扩展
```sql
CREATE EXTENSION IF NOT EXISTS ltree;
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS btree_gin;
```

---

## 3. 开发环境搭建

### 3.1 克隆仓库
```bash
git clone <repository-url>
cd ndr
```

### 3.2 方式一: Docker Compose (推荐)
```bash
# 启动所有服务 (PostgreSQL + 应用)
docker compose up --build

# 后台运行
docker compose up -d --build

# 查看日志
docker compose logs -f app

# 停止服务
docker compose down

# 完全清理 (包括数据卷)
docker compose down -v
```

访问: http://localhost:8000

### 3.3 方式二: 本地开发
#### 步骤 1: 创建虚拟环境
```bash
python3.11 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
```

#### 步骤 2: 安装依赖
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 步骤 3: 配置 Pre-commit 钩子
```bash
pip install pre-commit
pre-commit install
pre-commit run --all-files  # 验证安装
```

#### 步骤 4: 配置数据库
首次使用可执行 `cp .env.example .env`，然后在 `.env` 中填入基础参数:
```bash
DB_URL=postgresql+psycopg2://postgres:postgres@localhost:5432/ndr
DB_CONNECT_TIMEOUT=5
ENABLE_METRICS=true
API_KEY_ENABLED=false
TRACE_HTTP=false
AUTO_APPLY_MIGRATIONS=true
```

创建数据库:
```bash
# 使用 psql
createdb ndr

# 或通过 SQL
psql -U postgres -c "CREATE DATABASE ndr;"
```

#### 步骤 5: 运行迁移
```bash
alembic upgrade head
```

#### 步骤 6: 启动服务
```bash
# 开发模式 (自动重载)
uvicorn app.main:app --reload --port 9001

# 启用 HTTP 追踪 (调试用)
TRACE_HTTP=true uvicorn app.main:app --reload --host 0.0.0.0 --port 9001
```

### 3.4 验证安装
```bash
# 健康检查
curl http://localhost:8000/health

# 就绪检查 (包含数据库和迁移验证)
curl http://localhost:8000/ready

# 查看 API 文档
open http://localhost:8000/docs  # 或浏览器访问
```

---

## 4. 项目架构

### 4.1 目录结构
```
ndr/
├── app/                          # 应用主代码
│   ├── api/v1/                  # API 路由和模式定义
│   │   ├── routers/             # FastAPI 路由
│   │   │   ├── documents.py    # 文档 CRUD
│   │   │   ├── nodes.py        # 节点管理
│   │   │   └── relationships.py # 关系管理
│   │   ├── schemas/             # Pydantic 模型
│   │   └── deps.py              # 依赖注入
│   ├── app/services/            # 业务逻辑层
│   │   ├── document_service.py
│   │   ├── node_service.py
│   │   ├── relationship_service.py
│   │   ├── document_version_service.py
│   │   ├── bundle.py            # 服务工厂
│   │   └── base.py              # 基础服务类
│   ├── domain/repositories/     # 数据访问层
│   │   ├── document_repository.py
│   │   ├── node_repository.py
│   │   └── relationship_repository.py
│   ├── infra/                   # 基础设施层
│   │   ├── db/
│   │   │   ├── models.py        # SQLAlchemy 模型
│   │   │   ├── session.py       # 数据库会话
│   │   │   └── types.py         # 自定义类型
│   │   └── observability/
│   │       ├── metrics.py       # Prometheus 指标
│   │       └── middleware.py    # HTTP 中间件
│   ├── common/
│   │   ├── config.py            # 配置管理
│   │   ├── logging.py           # 日志配置
│   │   └── idempotency.py       # 幂等性处理
│   └── main.py                  # 应用入口
├── alembic/                     # 数据库迁移
│   └── versions/
├── tests/                       # 测试套件
├── scripts/                     # 工具脚本
├── docs/                        # 项目文档
└── docker-compose.yml
```

### 4.2 分层架构
```
┌─────────────────────────────┐
│   API Layer (routers)       │ ← FastAPI 路由、请求/响应模型
├─────────────────────────────┤
│   Service Layer             │ ← 业务逻辑、事务管理
├─────────────────────────────┤
│   Repository Layer          │ ← 数据访问、查询构建
├─────────────────────────────┤
│   Database (ORM Models)     │ ← SQLAlchemy 模型
└─────────────────────────────┘
```

### 4.3 数据模型关系
```
Node (层级树)
 ├── id, name, slug, path (ltree)
 ├── parent_id, position
 └── NodeDocument ──> Document
                       ├── id, title, metadata, content
                       └── DocumentVersion (审计历史)
```

### 4.4 关键设计模式
- **Repository Pattern**: 数据访问抽象
- **Service Bundle**: 共享会话的服务工厂
- **Soft Delete**: 逻辑删除而非物理删除
- **Idempotency**: 基于 Idempotency-Key 的幂等性保证
- **Versioning**: 自动版本快照和变更追踪

---

## 5. 数据库维护

### 5.1 数据库迁移

#### 创建新迁移
```bash
# 自动生成迁移 (基于模型变更)
alembic revision --autogenerate -m "描述变更内容"

# 手动创建空迁移
alembic revision -m "描述变更内容"
```

#### 执行迁移
```bash
# 升级到最新版本
alembic upgrade head

# 升级到指定版本
alembic upgrade <revision_id>

# 查看当前版本
alembic current

# 查看迁移历史
alembic history

# 降级 (谨慎使用)
alembic downgrade -1         # 降级一个版本
alembic downgrade <revision> # 降级到指定版本
```

#### 迁移最佳实践
1. **总是审查自动生成的迁移脚本**
2. **在开发环境测试迁移**: 先 upgrade 再 downgrade
3. **备份生产数据库**: 在执行迁移前务必备份
4. **使用事务**: 大部分迁移应在事务中执行
5. **数据迁移分离**: 复杂数据迁移单独编写脚本

### 5.2 数据库备份

#### 使用 pg_dump
```bash
# 完整备份
pg_dump -h localhost -U postgres -d ndr -F c -f ndr_backup_$(date +%Y%m%d_%H%M%S).dump

# 仅备份结构
pg_dump -h localhost -U postgres -d ndr --schema-only -f schema.sql

# 仅备份数据
pg_dump -h localhost -U postgres -d ndr --data-only -f data.sql

# 备份特定表
pg_dump -h localhost -U postgres -d ndr -t documents -t nodes -F c -f partial_backup.dump
```

#### 恢复备份
```bash
# 从自定义格式恢复
pg_restore -h localhost -U postgres -d ndr_new -c ndr_backup.dump

# 从 SQL 文件恢复
psql -h localhost -U postgres -d ndr_new -f backup.sql
```

#### 自动备份脚本
创建 `/usr/local/bin/backup-ndr.sh`:
```bash
#!/bin/bash
BACKUP_DIR="/var/backups/ndr"
DB_NAME="ndr"
DB_USER="postgres"
RETENTION_DAYS=7

mkdir -p $BACKUP_DIR
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/ndr_$TIMESTAMP.dump"

pg_dump -h localhost -U $DB_USER -d $DB_NAME -F c -f $BACKUP_FILE

# 压缩备份
gzip $BACKUP_FILE

# 删除旧备份
find $BACKUP_DIR -name "ndr_*.dump.gz" -mtime +$RETENTION_DAYS -delete

echo "Backup completed: $BACKUP_FILE.gz"
```

添加到 crontab:
```bash
# 每天凌晨 2 点备份
0 2 * * * /usr/local/bin/backup-ndr.sh >> /var/log/ndr-backup.log 2>&1
```

### 5.3 数据库维护任务

#### 清理软删除数据
```sql
-- 查看软删除数据统计
SELECT
  'documents' as table_name,
  COUNT(*) as deleted_count
FROM documents
WHERE deleted_at IS NOT NULL
UNION ALL
SELECT
  'nodes',
  COUNT(*)
FROM nodes
WHERE deleted_at IS NOT NULL;

-- 永久删除超过 90 天的软删除记录 (谨慎操作)
DELETE FROM documents
WHERE deleted_at IS NOT NULL
  AND deleted_at < NOW() - INTERVAL '90 days';

DELETE FROM nodes
WHERE deleted_at IS NOT NULL
  AND deleted_at < NOW() - INTERVAL '90 days';
```

#### 清理过期幂等性记录
```sql
-- 幂等性记录会自动过期 (24小时)，但可以手动清理
DELETE FROM idempotency_records
WHERE expires_at < NOW();
```

#### 数据库性能维护
```sql
-- 更新统计信息
ANALYZE documents;
ANALYZE nodes;
ANALYZE node_documents;

-- 重建索引 (定期维护)
REINDEX TABLE documents;
REINDEX TABLE nodes;

-- 清理死元组
VACUUM ANALYZE documents;
VACUUM ANALYZE nodes;
```

### 5.4 监控数据库大小
```sql
-- 查看表大小
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 查看索引大小
SELECT
  schemaname,
  tablename,
  indexname,
  pg_size_pretty(pg_relation_size(schemaname||'.'||indexname)) AS size
FROM pg_indexes
WHERE schemaname = 'public'
ORDER BY pg_relation_size(schemaname||'.'||indexname) DESC;
```

---

## 6. 常见维护任务

### 6.1 代码质量检查

#### 运行 Pre-commit 钩子
```bash
# 手动运行所有检查
pre-commit run --all-files

# 运行特定钩子
pre-commit run ruff --all-files
pre-commit run mypy --all-files
```

#### 代码格式化
```bash
# 使用 black 格式化
black app/ tests/

# 使用 isort 排序导入
isort app/ tests/

# 使用 ruff 自动修复
ruff check --fix app/ tests/
```

#### 类型检查
```bash
# 运行 mypy
mypy app/

# 忽略已知问题
mypy app/ --no-error-summary
```

### 6.2 测试

#### 运行测试套件
```bash
# 运行所有测试
pytest

# 详细输出
pytest -v

# 运行特定测试文件
pytest tests/api/test_api_crud.py

# 运行特定测试
pytest tests/api/test_api_crud.py::test_create_document

# 显示打印输出
pytest -s

# 并行运行 (需要 pytest-xdist)
pytest -n auto

# 生成覆盖率报告
pytest --cov=app --cov-report=html
```

#### 测试环境配置
在运行 pytest 前确保设置 PostgreSQL 连接，例如:
```bash
export TEST_DB_URL=postgresql+psycopg2://postgres:postgres@localhost:5432/ndr_test
export DESTRUCTIVE_API_KEY=test-admin-key  # 覆盖默认管理员密钥
```
如需持久化这些变量，可以将它们写入 `.env`，或使用 `dotenv -f env.test run pytest` 等方式在执行前手动加载。

#### 测试数据库设置
```bash
# 创建测试数据库
createdb ndr_test

# 测试会自动运行迁移和清理
pytest
```

### 6.3 依赖管理

#### 更新依赖
```bash
# 查看过期依赖
pip list --outdated

# 更新特定包
pip install --upgrade fastapi

# 更新所有依赖 (谨慎)
pip install --upgrade -r requirements.txt

# 更新后重新导出依赖
pip freeze > requirements.txt
```

#### 安全审计
```bash
# 使用 pip-audit 检查安全漏洞
pip install pip-audit
pip-audit

# 使用 safety
pip install safety
safety check
```

### 6.4 导出 OpenAPI 文档
```bash
# 导出 OpenAPI JSON
python scripts/export_openapi.py /path/to/output/directory

# 访问在线文档
# Swagger UI: http://localhost:8000/docs
# ReDoc: http://localhost:8000/redoc
```

### 6.5 性能基准测试
```bash
# ltree 索引性能测试
python scripts/benchmark_ltree.py \
  --index gist \
  --index gin \
  --samples 30 \
  --breadth 5 \
  --depth 4
```

---

## 7. 故障排查

### 7.1 应用无法启动

#### 问题: 数据库连接失败
```
sqlalchemy.exc.OperationalError: could not connect to server
```

**解决方案:**
1. 检查数据库是否运行:
   ```bash
   pg_isready -h localhost -p 5432
   ```
2. 验证 DB_URL 配置:
   ```bash
   echo $DB_URL
   ```
3. 检查数据库凭据:
   ```bash
   psql -h localhost -U postgres -d ndr
   ```

#### 问题: 迁移失败
```
alembic.util.exc.CommandError: Can't locate revision identified by 'xxxx'
```

**解决方案:**
1. 检查当前版本:
   ```bash
   alembic current
   ```
2. 查看迁移历史:
   ```bash
   alembic history
   ```
3. 强制标记版本 (谨慎):
   ```bash
   alembic stamp head
   ```

#### 问题: ltree 扩展缺失
```
ERROR: type "ltree" does not exist
```

**解决方案:**
```sql
-- 连接到数据库
psql -U postgres -d ndr

-- 创建扩展
CREATE EXTENSION IF NOT EXISTS ltree;
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS btree_gin;
```

### 7.2 性能问题

#### 问题: API 响应缓慢

**诊断步骤:**
1. 检查 Prometheus 指标:
   ```bash
   curl http://localhost:8000/metrics | grep http_request_duration
   ```

2. 查看慢查询日志:
   ```sql
   -- 启用慢查询日志
   ALTER SYSTEM SET log_min_duration_statement = 1000; -- 1秒
   SELECT pg_reload_conf();
   ```

3. 分析查询计划:
   ```sql
   EXPLAIN ANALYZE
   SELECT * FROM nodes
   WHERE path <@ '1.2.3';
   ```

**常见优化:**
- 确保 ltree 索引存在: `CREATE INDEX IF NOT EXISTS ix_nodes_path_tree ON nodes USING GIST (path);`
- 增加连接池大小 (在 `app/infra/db/session.py`)
- 优化分页查询: 使用游标分页而非 offset

#### 问题: 内存占用过高

**诊断:**
```bash
# 查看进程内存
ps aux | grep uvicorn

# 使用 memory_profiler
pip install memory_profiler
python -m memory_profiler app/main.py
```

**解决方案:**
- 减少 `TRACE_HTTP` 日志量
- 限制查询结果集大小
- 调整 SQLAlchemy 连接池参数

### 7.3 数据一致性问题

#### 问题: 节点路径不一致

**检测:**
```sql
-- 检查路径不一致的节点
SELECT
  id,
  name,
  parent_id,
  path::text,
  parent_path
FROM nodes
WHERE parent_id IS NOT NULL
  AND path::text NOT LIKE parent_path || '.%';
```

**修复:** (需根据实际情况调整)
```python
# 编写数据修复脚本
# scripts/fix_node_paths.py
```

#### 问题: 孤立的关系记录

**检测:**
```sql
-- 查找引用已删除文档的关系
SELECT nd.*
FROM node_documents nd
LEFT JOIN documents d ON nd.document_id = d.id
WHERE d.id IS NULL OR d.deleted_at IS NOT NULL;

-- 查找引用已删除节点的关系
SELECT nd.*
FROM node_documents nd
LEFT JOIN nodes n ON nd.node_id = n.id
WHERE n.id IS NULL OR n.deleted_at IS NOT NULL;
```

**清理:**
```sql
-- 删除孤立关系 (谨慎操作)
DELETE FROM node_documents
WHERE document_id IN (
  SELECT id FROM documents WHERE deleted_at IS NOT NULL
);
```

---

## 8. 性能优化

### 8.1 数据库优化

#### 索引优化
```sql
-- 检查缺失的索引
SELECT
  schemaname,
  tablename,
  attname,
  n_distinct,
  correlation
FROM pg_stats
WHERE schemaname = 'public'
  AND n_distinct > 100
ORDER BY n_distinct DESC;

-- 为常用查询添加索引
CREATE INDEX CONCURRENTLY idx_documents_metadata_gin
ON documents USING GIN (metadata);

CREATE INDEX CONCURRENTLY idx_documents_created_at
ON documents (created_at)
WHERE deleted_at IS NULL;
```

#### 连接池配置
编辑 `app/infra/db/session.py`:
```python
engine = create_engine(
    settings.DB_URL,
    pool_size=20,          # 增加连接池大小
    max_overflow=40,       # 增加溢出连接数
    pool_pre_ping=True,    # 连接健康检查
    pool_recycle=3600,     # 1小时回收连接
    echo=False,
)
```

### 8.2 应用优化

#### 启用查询缓存 (调用方实现)
NDR 本身不提供缓存，但调用方可以:
```python
# 示例: 使用 Redis 缓存文档查询
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_document(doc_id: int):
    cache_key = f"document:{doc_id}"
    cached = redis_client.get(cache_key)

    if cached:
        return json.loads(cached)

    # 调用 NDR API
    response = requests.get(f"http://ndr/api/v1/documents/{doc_id}")
    data = response.json()

    # 缓存 5 分钟
    redis_client.setex(cache_key, 300, json.dumps(data))
    return data
```

#### 批量操作
```python
# 使用批量 reorder 而非逐个更新
requests.post("/api/v1/nodes/reorder", json={
    "reorder_list": [
        {"node_id": 1, "new_position": 0},
        {"node_id": 2, "new_position": 1},
        {"node_id": 3, "new_position": 2},
    ]
})
```

### 8.3 监控指标

关键指标:
- **http_request_duration_seconds**: 请求延迟
- **http_requests_total**: 请求总数
- **数据库连接数**: 监控连接池使用情况
- **查询响应时间**: 慢查询数量
- **错误率**: 4xx/5xx 响应占比

设置 Prometheus 告警:
```yaml
# prometheus/alerts.yml
groups:
  - name: ndr_alerts
    interval: 30s
    rules:
      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 1
        for: 5m
        annotations:
          summary: "NDR API 高延迟"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 2m
        annotations:
          summary: "NDR API 错误率过高"
```

---

## 9. 安全配置

### 9.1 API 密钥配置

#### 启用 API 密钥认证
```bash
# .env.production
API_KEY_ENABLED=true
API_KEY=your-secure-api-key-here-min-32-chars
DESTRUCTIVE_API_KEY=your-admin-key-here-min-32-chars
```

#### 生成安全密钥
```bash
# 使用 openssl 生成随机密钥
openssl rand -hex 32

# 或使用 Python
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

#### 客户端使用
```bash
# 普通 API 调用
curl -H "X-Api-Key: your-secure-api-key" \
     http://localhost:8000/api/v1/documents

# 高危操作 (purge)
curl -X POST \
     -H "X-Api-Key: your-secure-api-key" \
     -H "X-Admin-Key: your-admin-key" \
     http://localhost:8000/api/v1/documents/123/purge
```

### 9.2 CORS 配置

#### 启用 CORS
```bash
CORS_ENABLED=true
CORS_ORIGINS=https://example.com,https://app.example.com
```

#### 参数说明
应用会在启动时通过 `app/common/config.py` 中的 `_as_list` 函数按逗号拆分 `CORS_ORIGINS`，无需额外修改代码即可生效。

### 9.3 数据库安全

#### 使用专用数据库用户
```sql
-- 创建专用用户
CREATE USER ndr_app WITH PASSWORD 'strong-password';

-- 授予最小权限
GRANT CONNECT ON DATABASE ndr TO ndr_app;
GRANT USAGE ON SCHEMA public TO ndr_app;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO ndr_app;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO ndr_app;

-- 更新 DB_URL
DB_URL=postgresql+psycopg2://ndr_app:strong-password@localhost:5432/ndr
```

#### 启用 SSL 连接
```bash
DB_URL=postgresql+psycopg2://user:pass@host:5432/ndr?sslmode=require
```

### 9.4 日志安全

#### 禁用生产环境的 TRACE_HTTP
```bash
# 生产环境必须设置
TRACE_HTTP=false
```

#### 日志脱敏
在 `app/common/logging.py` 中添加脱敏逻辑:
```python
def sanitize_log_data(data: dict) -> dict:
    """移除敏感字段"""
    sensitive_keys = {"password", "token", "api_key", "secret"}
    return {
        k: "***REDACTED***" if k.lower() in sensitive_keys else v
        for k, v in data.items()
    }
```

---

## 10. 监控与日志

### 10.1 日志管理

#### 日志格式
NDR 使用结构化 JSON 日志:
```json
{
  "timestamp": "2024-10-24T10:30:45.123Z",
  "level": "INFO",
  "logger": "http",
  "message": "Request completed",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "method": "GET",
  "path": "/api/v1/documents/123",
  "status_code": 200,
  "duration_ms": 45.2,
  "client_ip": "192.168.1.100",
  "user_id": "user-123"
}
```

#### 日志级别
当前日志级别固定为 INFO，如需调整请修改 `app/common/logging.py` 后重新部署。

#### 日志输出到文件
```bash
# 使用 systemd 或容器日志驱动
uvicorn app.main:app --log-config logging.yaml 2>&1 | tee /var/log/ndr/app.log
```

#### 集成 ELK/Loki
由于使用 JSON 格式，可直接配置 Filebeat/Promtail:

**Filebeat 配置示例:**
```yaml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/ndr/*.log
    json.keys_under_root: true
    json.add_error_key: true

output.elasticsearch:
  hosts: ["localhost:9200"]
  index: "ndr-logs-%{+yyyy.MM.dd}"
```

### 10.2 Prometheus 监控

#### 启用指标
```bash
ENABLE_METRICS=true
```

#### 配置 Prometheus
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'ndr'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 15s
```

#### 关键指标
```promql
# 平均请求延迟 (95 分位)
histogram_quantile(0.95,
  rate(http_request_duration_seconds_bucket[5m])
)

# 每秒请求数
rate(http_requests_total[1m])

# 错误率
sum(rate(http_requests_total{status=~"5.."}[5m]))
/
sum(rate(http_requests_total[5m]))
```

#### Grafana 仪表盘
导入预配置仪表盘 (需创建):
- 请求速率和延迟
- 错误率和状态码分布
- 数据库连接池状态
- Top 10 慢接口

### 10.3 健康检查

#### Kubernetes 探针配置
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ndr-app
spec:
  containers:
    - name: ndr
      image: ndr:latest
      livenessProbe:
        httpGet:
          path: /health
          port: 8000
        initialDelaySeconds: 10
        periodSeconds: 30
      readinessProbe:
        httpGet:
          path: /ready
          port: 8000
        initialDelaySeconds: 5
        periodSeconds: 10
```

#### 自定义健康检查脚本
```bash
#!/bin/bash
# /usr/local/bin/ndr-healthcheck.sh

HEALTH_URL="http://localhost:8000/health"
READY_URL="http://localhost:8000/ready"

if ! curl -f -s $HEALTH_URL > /dev/null; then
  echo "Health check failed"
  exit 1
fi

if ! curl -f -s $READY_URL > /dev/null; then
  echo "Readiness check failed"
  exit 1
fi

echo "All checks passed"
exit 0
```

---

## 11. 部署指南

### 11.1 Docker 部署

#### 构建镜像
```bash
# 单平台构建
docker build -t ndr:latest .

# 多平台构建 (需要 buildx)
docker buildx build --platform linux/amd64,linux/arm64 -t ndr:latest .
```

#### 运行容器
```bash
docker run -d \
  --name ndr-app \
  -p 8000:8000 \
  -e DB_URL="postgresql+psycopg2://user:pass@host:5432/ndr" \
  -e API_KEY_ENABLED=true \
  -e API_KEY="your-api-key" \
  --restart unless-stopped \
  ndr:latest
```

### 11.2 Kubernetes 部署

#### ConfigMap
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ndr-config
data:
  DB_CONNECT_TIMEOUT: "5"
  ENABLE_METRICS: "true"
  AUTO_APPLY_MIGRATIONS: "true"
  TRACE_HTTP: "false"
```

#### Secret
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: ndr-secrets
type: Opaque
stringData:
  DB_URL: postgresql+psycopg2://user:pass@postgres:5432/ndr
  API_KEY: your-secure-api-key
  DESTRUCTIVE_API_KEY: your-admin-key
```

#### Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ndr
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ndr
  template:
    metadata:
      labels:
        app: ndr
    spec:
      containers:
        - name: ndr
          image: ndr:latest
          ports:
            - containerPort: 8000
          envFrom:
            - configMapRef:
                name: ndr-config
            - secretRef:
                name: ndr-secrets
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8000
            initialDelaySeconds: 5
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "2000m"
```

#### Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: ndr-service
spec:
  selector:
    app: ndr
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```

### 11.3 Systemd 服务

#### 创建服务文件
```ini
# /etc/systemd/system/ndr.service
[Unit]
Description=NDR Document Management Service
After=network.target postgresql.service

[Service]
Type=simple
User=ndr
Group=ndr
WorkingDirectory=/opt/ndr
Environment="PATH=/opt/ndr/.venv/bin:/usr/local/bin:/usr/bin:/bin"
EnvironmentFile=/opt/ndr/.env.production
ExecStart=/opt/ndr/.venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

#### 启用服务
```bash
sudo systemctl daemon-reload
sudo systemctl enable ndr
sudo systemctl start ndr
sudo systemctl status ndr
```

### 11.4 反向代理 (Nginx)

```nginx
upstream ndr_backend {
    server 127.0.0.1:8000;
    # 负载均衡多实例
    # server 127.0.0.1:8001;
    # server 127.0.0.1:8002;
}

server {
    listen 80;
    server_name ndr.example.com;

    # 重定向到 HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name ndr.example.com;

    ssl_certificate /etc/letsencrypt/live/ndr.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/ndr.example.com/privkey.pem;

    client_max_body_size 100M;

    location / {
        proxy_pass http://ndr_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # 超时配置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    location /metrics {
        # 限制 metrics 访问
        allow 10.0.0.0/8;
        deny all;
        proxy_pass http://ndr_backend;
    }
}
```

---

## 12. 备份与恢复

### 12.1 完整备份策略

#### 三级备份方案
1. **每日增量备份**: WAL 归档
2. **每周完整备份**: pg_dump
3. **每月归档**: 冷备份到对象存储

#### WAL 归档配置
```sql
-- postgresql.conf
wal_level = replica
archive_mode = on
archive_command = 'test ! -f /mnt/wal_archive/%f && cp %p /mnt/wal_archive/%f'
```

#### 自动备份脚本
```bash
#!/bin/bash
# /usr/local/bin/ndr-full-backup.sh

set -e

BACKUP_DIR="/var/backups/ndr"
S3_BUCKET="s3://my-backup-bucket/ndr"
DB_NAME="ndr"
RETENTION_DAYS=30

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/full_backup_$TIMESTAMP.dump"

# 完整备份
pg_dump -h localhost -U postgres -d $DB_NAME -F c -f $BACKUP_FILE

# 压缩
gzip $BACKUP_FILE

# 上传到 S3 (需要 aws cli)
aws s3 cp $BACKUP_FILE.gz $S3_BUCKET/

# 删除本地旧备份
find $BACKUP_DIR -name "full_backup_*.dump.gz" -mtime +$RETENTION_DAYS -delete

# 验证备份
VERIFY_DB="ndr_verify_$TIMESTAMP"
createdb $VERIFY_DB
pg_restore -d $VERIFY_DB $BACKUP_FILE.gz
psql -d $VERIFY_DB -c "SELECT COUNT(*) FROM documents;"
dropdb $VERIFY_DB

echo "Backup completed and verified: $BACKUP_FILE.gz"
```

### 12.2 灾难恢复

#### 完整恢复流程
```bash
# 1. 停止应用
sudo systemctl stop ndr

# 2. 创建新数据库
createdb ndr_new

# 3. 恢复备份
gunzip -c /var/backups/ndr/full_backup_20241024.dump.gz | \
  pg_restore -d ndr_new -c

# 4. 验证数据
psql -d ndr_new -c "SELECT COUNT(*) FROM documents;"
psql -d ndr_new -c "SELECT COUNT(*) FROM nodes;"

# 5. 切换数据库
psql -U postgres -c "ALTER DATABASE ndr RENAME TO ndr_old;"
psql -U postgres -c "ALTER DATABASE ndr_new RENAME TO ndr;"

# 6. 重启应用
sudo systemctl start ndr

# 7. 验证服务
curl http://localhost:8000/ready
```

#### 时间点恢复 (PITR)
```bash
# 使用 WAL 归档恢复到特定时间点
pg_basebackup -h localhost -D /var/lib/postgresql/data_pitr -U postgres -P

# 配置 recovery.conf
cat > /var/lib/postgresql/data_pitr/recovery.conf << EOF
restore_command = 'cp /mnt/wal_archive/%f %p'
recovery_target_time = '2024-10-24 10:30:00'
EOF

# 启动恢复
pg_ctl -D /var/lib/postgresql/data_pitr start
```

### 12.3 数据导出与导入

#### 导出特定数据
```sql
-- 导出特定节点子树
COPY (
  SELECT * FROM nodes
  WHERE path <@ '1.2.3'::ltree
) TO '/tmp/subtree_nodes.csv' WITH CSV HEADER;

-- 导出文档
COPY (
  SELECT * FROM documents
  WHERE type = 'article'
) TO '/tmp/articles.csv' WITH CSV HEADER;
```

#### 导入数据
```sql
-- 导入节点
COPY nodes FROM '/tmp/subtree_nodes.csv' WITH CSV HEADER;

-- 导入文档
COPY documents FROM '/tmp/articles.csv' WITH CSV HEADER;
```

---

## 附录

### A. 环境变量完整列表

| 变量名 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| DB_URL | str | postgresql+psycopg2://...@localhost:5432/ndr | 数据库连接字符串 |
| DB_CONNECT_TIMEOUT | int | 5 | 连接超时 (秒) |
| TEST_DB_URL | str | None | 测试数据库 (可选) |
| ENABLE_METRICS | bool | true | 启用 Prometheus 指标 |
| API_KEY_ENABLED | bool | false | 启用 API 密钥认证 |
| API_KEY | str | None | API 密钥 |
| DESTRUCTIVE_API_KEY | str | None | 高危操作密钥 |
| CORS_ENABLED | bool | false | 启用 CORS |
| CORS_ORIGINS | list | [] | 允许的源 (逗号分隔) |
| AUTO_APPLY_MIGRATIONS | bool | true | 自动运行迁移 |
| TRACE_HTTP | bool | false | 记录完整请求/响应 |
| NDR_BASE_URL | str | http://localhost:9001 | `requests` 集成测试使用的基准地址 |
| RUN_REMOTE_REQUESTS_TEST | bool | false | 控制远程请求集成测试是否运行 |

### B. API 端点速查

| 方法 | 路径 | 说明 |
|------|------|------|
| GET | /health | 健康检查 |
| GET | /ready | 就绪检查 |
| GET | /metrics | Prometheus 指标 |
| GET | /docs | Swagger UI |
| POST | /api/v1/documents | 创建文档 |
| GET | /api/v1/documents/{id} | 获取文档 |
| PUT | /api/v1/documents/{id} | 更新文档 |
| DELETE | /api/v1/documents/{id} | 软删除文档 |
| POST | /api/v1/documents/{id}/restore | 恢复文档 |
| POST | /api/v1/documents/{id}/purge | 永久删除 |
| GET | /api/v1/documents | 列出文档 |
| POST | /api/v1/nodes | 创建节点 |
| GET | /api/v1/nodes/{id} | 获取节点 |
| PUT | /api/v1/nodes/{id} | 更新节点 |
| DELETE | /api/v1/nodes/{id} | 软删除节点 |
| POST | /api/v1/nodes/reorder | 批量重排序 |
| GET | /api/v1/nodes/{id}/descendants | 获取子树 |
| POST | /api/v1/relationships | 绑定关系 |
| DELETE | /api/v1/relationships | 解除关系 |

### C. 常用 SQL 查询

```sql
-- 查看节点树结构
SELECT
  REPEAT('  ', nlevel(path) - 1) || name as tree,
  path::text,
  id
FROM nodes
WHERE deleted_at IS NULL
ORDER BY path;

-- 查找文档关联的所有节点
SELECT n.*
FROM nodes n
JOIN node_documents nd ON n.id = nd.node_id
WHERE nd.document_id = 123;

-- 查找节点下的所有文档 (含子树)
SELECT DISTINCT d.*
FROM documents d
JOIN node_documents nd ON d.id = nd.document_id
JOIN nodes n ON nd.node_id = n.id
WHERE n.path <@ (SELECT path FROM nodes WHERE id = 456)::ltree;

-- 统计各类型文档数量
SELECT
  COALESCE(type, 'NULL') as type,
  COUNT(*) as count,
  COUNT(*) FILTER (WHERE deleted_at IS NOT NULL) as deleted_count
FROM documents
GROUP BY type;

-- 查找最近修改的文档
SELECT id, title, updated_at, updated_by
FROM documents
WHERE deleted_at IS NULL
ORDER BY updated_at DESC
LIMIT 10;
```

### D. 故障码速查

| 状态码 | error_code | 说明 |
|--------|-----------|------|
| 400 | bad_request | 请求参数错误 |
| 401 | unauthorized | 缺少或无效的 API 密钥 |
| 403 | forbidden | 权限不足 (如缺少管理员密钥) |
| 404 | not_found | 资源不存在 |
| 409 | conflict | 资源冲突 (如路径重复) |
| 422 | validation_error | Pydantic 验证失败 |
| 500 | internal_server_error | 服务器内部错误 |

### E. 联系方式

- **问题反馈**: 查看项目 issues 或联系开发团队
- **文档**: 参考 `docs/` 目录下的设计文档
- **API 文档**: http://localhost:8000/docs

---

**文档版本**: 1.0
**最后更新**: 2024-10-24
**适用版本**: NDR v0.1.0+
### 6.6 幂等记录清理

幂等记录表 `idempotency_records` 会保存 24 小时（默认）以支撑请求重放校验。建议配置定期清理任务：

```bash
# 预览将删除的数量（不执行删除）
.venv/bin/python scripts/cleanup_idempotency.py --dry-run

# 删除所有过期记录（expires_at <= now）
.venv/bin/python scripts/cleanup_idempotency.py

# 删除过期超过 72 小时的记录
.venv/bin/python scripts/cleanup_idempotency.py --hours 72
```

crontab 示例（每日凌晨执行）：

```cron
0 3 * * * cd /opt/ndr && /opt/ndr/.venv/bin/python scripts/cleanup_idempotency.py >> /var/log/ndr/cleanup.log 2>&1
```

### 6.7 TRACE_HTTP 脱敏

本地调试可设置 `TRACE_HTTP=true` 输出请求/响应体。为避免敏感信息泄露，中间件会对常见字段（如 `password`、`token`、`api_key`、`authorization` 等）进行掩码（`***`）。

提示：
- 对于非 JSON 的负载会采用简单文本正则掩码，尽力而为；
- 生产环境仍应保持 `TRACE_HTTP=false`；
- 如需扩展脱敏字段，可在 `app/infra/observability/middleware.py` 中调整 `SENSITIVE_KEYS`。
